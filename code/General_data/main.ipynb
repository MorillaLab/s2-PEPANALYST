{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fcff91-7a9c-4676-a3b7-1f699ace465d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install tape-proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6daaa9bc-b859-4df4-97ce-c04e85fee65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#HuggingFace Tranformers Package\n",
    "# pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9674aec7-b4b6-4ef2-b671-b489b06ae3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a8ecfd-54c6-4f76-aefd-5f9d1e58deb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import os \n",
    "from scipy.stats import norm\n",
    "import scipy.stats as sps\n",
    "import cv2\n",
    "from scipy.ndimage import convolve\n",
    "import skimage\n",
    "from scipy import ndimage\n",
    "from scipy.spatial.distance import cdist\n",
    "from nibabel.testing import data_path\n",
    "import nibabel as nib\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import os\n",
    "import pandas as pd\n",
    "import skimage.measure\n",
    "import seaborn as sns\n",
    "import scipy as sp\n",
    "import gudhi as gd\n",
    "import random\n",
    "import sys\n",
    "sys.path.append('../../') \n",
    "from Code.function_geometry import * \n",
    "from Code.codegeometry import * \n",
    "from PIL import Image\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32bb0e7-b976-4f46-b7e4-719786dd746d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.preprocessing   as skp\n",
    "import sklearn.neighbors       as skn\n",
    "import sklearn.model_selection as skm\n",
    "import sklearn.decomposition   as skd\n",
    "import sklearn.manifold        as skf\n",
    "import sklearn.pipeline        as skl\n",
    "import sklearn.svm             as sks\n",
    "import sklearn.ensemble        as ske\n",
    "import itertools\n",
    "import tensorflow as tf\n",
    "\n",
    "import gudhi.clustering.tomato as gdt\n",
    "import gudhi.representations   as gdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c0b128-f5bd-4b2d-bef7-c606df926703",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "#tokenizer\n",
    "from tape import ProteinBertModel, TAPETokenizer\n",
    "# from tape import UniRepModel, UniRepTokenizer\n",
    "# from tape import ProteinBertModel, ProteinBertTokenizer\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import BertModel, BertTokenizer\n",
    "# ProtGPT2\n",
    "# from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1bca02-d924-4210-a3c9-9aca8b3fe004",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3099e6e0-b4e1-4a7c-a665-f2f47bef1a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D,Conv2D, Dense, Flatten, Dropout,MaxPooling2D\n",
    "from keras import layers\n",
    "from keras.layers import MaxPooling1D,MaxPooling2D\n",
    "from keras.optimizers import SGD, RMSprop\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc50ffc-f4f0-4bcd-b0c8-1c6f056646ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createFaster(filename,labels,sequences):\n",
    "    with open(filename, 'w') as f:\n",
    "        # Write content to the file\n",
    "        for i in range(len(sequences)):\n",
    "        # for i in range(5):\n",
    "            f.write(\">\"+str(labels[i]))\n",
    "            f.write(sequences[i]+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10538ffe-d891-4d55-b1ce-384edbb908c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def signalProtein(filename,sequences,labels):\n",
    "    new_label = []\n",
    "    new_sequence = []\n",
    "    i = 0\n",
    "    with open(filename, 'w') as f:\n",
    "        for r in result_signalp:\n",
    "            if r > 0 and r < 0.7:\n",
    "                new_label.append(0)\n",
    "            elif r > 0.7:\n",
    "                new_label.append(1)\n",
    "            if r > 0:\n",
    "                f.write(labels[i]+\"\\n\")\n",
    "                f.write(sequences[i]+\"\\n\")\n",
    "                new_sequence.append(sequences[i])\n",
    "            i+=1\n",
    "    return new_label,new_sequence         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56934c03-d05d-4893-8897-55963242ef93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resultSignalP(filename):\n",
    "    f=open(filename,'r')\n",
    "    result=[]\n",
    "    next(f)\n",
    "    next(f)\n",
    "    for line in f.readlines():\n",
    "        data = line.rstrip()  \n",
    "        index = data.__contains__('SP')\n",
    "        #Can we return the probabilty of SP and other\n",
    "        if index == True: \n",
    "            result.append(1)\n",
    "        else:\n",
    "            result.append(0)\n",
    "    f.close()\n",
    "    return result  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c8c842-1894-42f7-bece-7b2ea00f2d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def geotop_analysis(data):\n",
    "    # U_train = U_train_b + U_train_m + U_test_b + U_test_m\n",
    "    n = 100\n",
    "    i = 0\n",
    "    dgms_tda = []\n",
    "    dgms_per_var = []\n",
    "    dgms_per_linalg = []\n",
    "    for U in data:\n",
    "        print(i)\n",
    "        L = np.linspace(np.min(U), np.max(U),  n)[::-1]\n",
    "        life, barecode, persistence, connected_comp, Per_total, Area_total, euler_total, per, area, euler = function_persistance(U, L, False)\n",
    "        diagram_pondere_total_vari = np.zeros((len(life), 2))\n",
    "        diagram_pondere_linalg = np.zeros((len(life), 2))\n",
    "        diagram = np.zeros((len(life), 2))\n",
    "        k = 0\n",
    "        idx_keys = list(life.keys())\n",
    "        for idx in idx_keys[1:]:\n",
    "            diagram_pondere_total_vari[k][0] = (np.sum(per[idx]))*life[idx][1]\n",
    "            diagram_pondere_total_vari[k][1] = (np.sum(per[idx]))*life[idx][0]\n",
    "            diagram_pondere_linalg[k][0] = (np.linalg.norm(per[idx]))*life[idx][1]\n",
    "            diagram_pondere_linalg[k][1] = (np.linalg.norm(per[idx]))*life[idx][0]\n",
    "            diagram[0] = life[idx][1]\n",
    "            diagram[1] = life[idx][0]\n",
    "            k=k+1\n",
    "        dgms_tda.append(diagram)\n",
    "        dgms_per_linalg.append(diagram_pondere_linalg)\n",
    "        dgms_per_var.append(diagram_pondere_total_vari)\n",
    "        i=i+1\n",
    "    return dgms_per_linalg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2f2107-2a49-4f7d-800c-e1769900333f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concate_embedding_geotop(embedding,dgms,dim):\n",
    "    long = embedding.shape[1]\n",
    "    res = []\n",
    "    i = 0\n",
    "    for array in dgms:\n",
    "        flat = array.flatten()\n",
    "        #flatten and concatenate the rest withe the remainning zeroes\n",
    "        t = dim - (long + flat.shape[0])\n",
    "        res.append(np.concatenate((np.concatenate((embedding[i], flat)), np.zeros(t))))\n",
    "        i +=1\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6aa1b5-5970-4b7b-98ae-a2f9384b093c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_trainning_saving(shape,epoch,model_name,train_data,train_labels,test_data,test_labels):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(filters=8, kernel_size=(3, 3), padding=\"same\",activation='relu', input_shape=(shape[0],shape[1],1)))\n",
    "    model.add(layers.AveragePooling2D())\n",
    "    \n",
    "    model.add(layers.Conv2D(filters=16, kernel_size=(3, 3), padding=\"same\",activation='relu'))\n",
    "    model.add(layers.AveragePooling2D())\n",
    "    \n",
    "    model.add(layers.Conv2D(filters=32, kernel_size=(3, 3),padding=\"same\", activation='relu'))\n",
    "    model.add(layers.AveragePooling2D())\n",
    "    \n",
    "    \n",
    "    model.add(layers.Flatten())\n",
    "    \n",
    "    model.add(layers.Dense(units=128, activation='relu',kernel_regularizer=regularizers.l2(1e-4),bias_regularizer=regularizers.l2(1e-4), activity_regularizer=regularizers.l2(1e-5)))\n",
    "    \n",
    "    model.add(layers.Dense(units=64, activation='relu',kernel_regularizer=regularizers.l2(1e-4),bias_regularizer=regularizers.l2(1e-4),activity_regularizer=regularizers.l2(1e-5)))\n",
    "    \n",
    "    model.add(layers.Dense(units=1, activation = 'sigmoid',kernel_regularizer=regularizers.l2(1e-4),bias_regularizer=regularizers.l2(1e-4),activity_regularizer=regularizers.l2(1e-5)))\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    print(model.summary())\n",
    "\n",
    "    #trainning\n",
    "    history = model.fit(x=train_data, y=train_labels,epochs=epoch,shuffle=True,validation_data=(test_data, test_labels),verbose=1,batch_size=64)\n",
    "  \n",
    "    \n",
    "    # Plot history: MAE\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.plot(history.history['accuracy'], label='training data')\n",
    "    plt.plot(history.history['val_accuracy'], label='validation data')\n",
    "    #plt.title('')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('No. epoch')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    model.save(model_name+'.h5')\n",
    "  \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d47cb43-494d-4ce0-b4ea-3ea2704e414d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Keras version:\", keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75174dd-f005-474a-96e5-61ffb8784c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concate_embedding_geotop(embedding,dgms,dim):\n",
    "    # len_data = max(array.shape[0] for array in dgms)\n",
    "    long = embedding.shape[1]\n",
    "    res = []\n",
    "    i = 0\n",
    "    for array in dgms:\n",
    "        flat = array.flatten()\n",
    "        #flatten and concatenate the rest with zeroes\n",
    "        t = dim - (long + flat.shape[0])\n",
    "        res.append(np.concatenate((np.concatenate([embedding[i], flat]), np.zeros(t))))\n",
    "        i +=1\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2658c6d1-108f-4613-87f3-29312896d9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_embedding_geotop(dgms,dim):\n",
    "    # len_data = max(array.shape[0] for array in dgms)\n",
    "    res = []\n",
    "    for array in dgms:\n",
    "        flat = array.flatten()\n",
    "        #flatten and concatenate the rest with zeroes\n",
    "        t = dim - flat.shape[0]\n",
    "        res.append(np.concatenate([flat, np.zeros(t)]))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa77e276-b933-4a51-8898-7de32dce7d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sp_no_sp(label):\n",
    "    if label == \"NO_SP\":\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692f067f-bd85-4ba2-bdd9-31e1fbdd5e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readFastaFiles(filename):\n",
    "    sequences = []\n",
    "    labels = []\n",
    "    with open(filename, 'r') as file:\n",
    "        current_id = None\n",
    "        current_seq = ''\n",
    "        skip_line = False\n",
    "        for line in file:\n",
    "            # print(\"*\"*10)\n",
    "            # print(line)\n",
    "            if not skip_line:\n",
    "                if line.startswith('>'):\n",
    "                    if current_id:\n",
    "                        # print(sp_no_sp(current_id.strip()[1:].split(\"|\")[2]),current_id.strip()[1:].split(\"|\")[2])\n",
    "                        labels.append(sp_no_sp(current_id.strip()[1:].split(\"|\")[2]))\n",
    "                        sequences.append(current_seq.replace('\\n', ''))\n",
    "                        # skip_line = not skip_line\n",
    "                    current_id = line\n",
    "                    current_seq = ''\n",
    "                else:\n",
    "                    current_seq += line\n",
    "                    skip_line = not skip_line\n",
    "            else:\n",
    "                skip_line = not skip_line\n",
    "        # Add the last sequence\n",
    "        if current_id:\n",
    "            labels.append(sp_no_sp(current_id.strip()[1:].split(\"|\")[2]))\n",
    "            sequences.append(current_seq.replace('\\n', ''))\n",
    "    return labels,sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deae36aa-737c-4a3f-b90d-630c382421fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "label,sequence=readFastaFiles(\"dataset.fasta\")  # change to your own path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3c71e3-3f2e-4f05-891e-39e44d66a995",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3b6606-b73e-43d0-9781-7c8e3e73aaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(label)[0].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e5c8b0-3770-463b-82ae-1afae66091ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.value_counts(pd.DataFrame(label)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ee7e84-bd8c-4edd-97de-742ae763020f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4d5a92-95e1-4da0-a180-c4578769c6ae",
   "metadata": {},
   "source": [
    "## Data Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7802f649-3055-4a4a-8d37-915ba42c2379",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating fasta file with protein <=200\n",
    "createFaster(\"all_data.fasta\",label,sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e17c3b-4fc2-4aa1-94f1-30377447bbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_label = label.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2beca74c-e9d5-4d65-9271-4d998ad7ba5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(new_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4bd6396-bdc7-4472-a419-c8d9336c8b9c",
   "metadata": {},
   "source": [
    "### Embedding using TAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46edf1d-4e6c-49f8-a6df-62f438b95aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Learning the representation of protein\n",
    "model_tape = ProteinBertModel.from_pretrained('bert-base')\n",
    "tokenizer_tape = TAPETokenizer(vocab='iupac')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b68a86-f855-4f10-9ce8-6b7b58623bab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_of_features = 768\n",
    "embedded=np.zeros((len(new_label),num_of_features))\n",
    "y=np.zeros(len(new_label))\n",
    "\n",
    "i=0\n",
    "for s in sequence:\n",
    "    #tape\n",
    "    print(i)\n",
    "    token_ids = torch.tensor([tokenizer_tape.encode(s)])\n",
    "    output = model_tape(token_ids)\n",
    "    sequence_output = output[0]\n",
    "    embedded[i]= np.array(np.mean(sequence_output.detach().numpy(),axis=1) )\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bb103e-f1c6-4880-85b6-430c236748fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the array to a file\n",
    "# np.save('alldata_tape.npy', embedded)\n",
    "\n",
    "# # Reload the array\n",
    "embedded = np.load('alldata_tape.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37136a1-ec50-45a8-8376-1a5c53ffc9a2",
   "metadata": {},
   "source": [
    "### Embedding using ESM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a944745-f532-4cfe-8cb5-2fa133a89cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "protein_data = [(\"protein_\" + str(i), s) for i, s in enumerate(sequence)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf136137-7952-4332-8ec6-ff07989ff829",
   "metadata": {},
   "outputs": [],
   "source": [
    "#embedding 2\n",
    "import torch\n",
    "import esm\n",
    "\n",
    "# Load ESM-2 model\n",
    "model, alphabet = esm.pretrained.esm2_t33_650M_UR50D()\n",
    "batch_converter = alphabet.get_batch_converter()\n",
    "model.eval()  # disables dropout for deterministic results\n",
    "\n",
    "def get_average_embedding(sequence):\n",
    "    _, _, batch_tokens = batch_converter(sequence)\n",
    "    # Get the embeddings\n",
    "    with torch.no_grad():\n",
    "        results = model(batch_tokens, repr_layers=[33], return_contacts=True)\n",
    "    # Compute the average embedding\n",
    "    avg_embedding = torch.mean(results[\"representations\"][33], dim=1)  # Assuming layer 33 for representation\n",
    "    return avg_embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9ece7a-9953-4723-9f29-7dc6c15ba7fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "embedding2 = []\n",
    "i = 0\n",
    "for s in protein_data:\n",
    "    print(i)\n",
    "    embedding2.append(get_average_embedding([s]))\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3f854c-aa33-4699-86f3-fd96501ee7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8eb0a1-a887-4b56-a263-e48efef2f1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the tensor to a file\n",
    "# torch.save(embedding2, 'alldata_esm.pt')\n",
    "\n",
    "# Load the tensor from the file\n",
    "embedding2 = torch.load('alldata_esm.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc497cc3-c150-48e0-827a-be57ca02f72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert each tensor to a NumPy array\n",
    "numpy_array_list = [tensor.numpy() for tensor in embedding2]\n",
    "\n",
    "# Convert the list of arrays to a single NumPy array\n",
    "numpy_array = np.array(numpy_array_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97dd069d-765d-4b93-a26e-b3cfa441d804",
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_array = numpy_array.reshape(numpy_array.shape[0],numpy_array.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576d20e5-51c5-4edd-a79d-9eaa01c6f9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b81e56-357c-4d8b-a90d-0f720ef70f2f",
   "metadata": {},
   "source": [
    "### Converting embedding to image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d862f22-887b-4f8d-8d1b-1aa394124b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_padded = np.concatenate((embedded, np.zeros((embedded.shape[0],16))), axis=1)\n",
    "embedding2_padded = np.concatenate((numpy_array, np.zeros((numpy_array.shape[0],16))), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e8602d-6816-4e16-a71c-e8fee608603f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('alldata_tape_scaled.npy', embedding_padded)\n",
    "np.save('alldata_esm_scaled.npy', embedding2_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994f1182-85c1-4a71-97cc-e35f31029f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding2_padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c798814b-774b-44a2-9484-6eec94e5936e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "std_scale = preprocessing.StandardScaler().fit(embedding_padded)\n",
    "embedding_normalized = std_scale.transform(embedding_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da27ac20-7203-4b0b-a002-39bef46cbbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_scale = preprocessing.StandardScaler().fit(embedding2_padded)\n",
    "embedding2_normalized = std_scale.transform(embedding2_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac146a2-192c-4d48-a9ed-ad0f510e3a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(embedding2_normalized[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88eb1060-1188-4df6-a5f4-776e94feed1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#first image\n",
    "shape_unit=28\n",
    "embedding_images=np.reshape(embedding_normalized,(embedding_normalized.shape[0],shape_unit,shape_unit))\n",
    "\n",
    "print(embedding_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72a9920-a1be-4fcd-aa4c-98ffaf61b69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_images[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56eb2ee2-406a-4962-9816-ea13c343360c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#first image\n",
    "shape_unit=36\n",
    "embedding2_images=np.reshape(embedding2_normalized,(embedding2_normalized.shape[0],shape_unit,shape_unit))\n",
    "\n",
    "# print(embedding2_images[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23150f1c-d10a-4d56-a745-c0327eacda70",
   "metadata": {},
   "source": [
    "### Getting the geometrical representation of each embedded image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff62603-0179-437b-82ac-fe44662b736e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#apply geotop to the first image embedding\n",
    "#28*28\n",
    "embedding_geotop = geotop_analysis(embedding_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a275bb5-4b6f-4abd-926a-480e58e05c5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "36*36\n",
    "embedding2_geotop = geotop_analysis(embedding2_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d055db1b-fa98-4659-81f2-166781c70c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding2_geotop[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc6126b-3775-447f-bda5-c9671edd40dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(\"alldata_tape_geotop.npz\", *embedding_geotop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbbd514-a461-46de-a873-b7f123375ec6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.savez(\"alldata_esm_geotop.npz\", *embedding2_geotop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fd2d8e-6fc2-44e0-9f3d-be8154d1aec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load list of NumPy arrays from file\n",
    "loaded_arrays = np.load(\"alldata_tape_geotop.npz\")\n",
    "loaded_arrays2 = np.load(\"alldata_esm_geotop.npz\")\n",
    "\n",
    "# # Access individual arrays using their keys\n",
    "# array1 = loaded_arrays['arr_0']\n",
    "# array2 = loaded_arrays['arr_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c90f8c3-3c78-4895-9a64-ee7c1e9c7755",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_geotop = [loaded_arrays['arr_'+str(i)] for i in range(len(loaded_arrays))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b5127d-2658-421b-b443-237053fb23cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding2_geotop = [loaded_arrays['arr_'+str(i)] for i in range(len(loaded_arrays2))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45cc005c-a706-41b7-9f1d-06cc1a2dcaf2",
   "metadata": {},
   "source": [
    "## Trainning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1796d48-ce03-4e50-b37a-afab49a52343",
   "metadata": {},
   "source": [
    "### TAPE and Geotop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b618c72-fac0-49cb-88b2-bc9b2b61fe39",
   "metadata": {},
   "outputs": [],
   "source": [
    "dgms = gdr.DiagramSelector(use=True, point_type='finite').fit_transform(embedding_geotop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4964a1b-5b24-4aea-9953-87a8c859f689",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dgms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a78f86-df1d-4e80-9ce6-151a273ecf9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 1024\n",
    "result = concate_embedding_geotop(embedded,dgms,dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b058613f-5491-4cc5-9a02-06e6433cd1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to be verify\n",
    "# shape_unit=32\n",
    "# tape_geotope_result = np.reshape(result,(X_normalized.shape[0],shape_unit,shape_unit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1b9979-7fa1-4524-864c-d6914fb28607",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356f52d2-5532-42ed-b56a-efc52a3a3762",
   "metadata": {},
   "outputs": [],
   "source": [
    "tape_geotope_result = result.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a32c1eb-baa2-4c19-806c-20d1e084b6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the dataset\n",
    "num_samples = len(result)\n",
    "num_train_samples = int(0.8 * num_samples)  # 80% for training, 20% for testing\n",
    "\n",
    "# Split data and labels into training and testing sets\n",
    "train_data, test_data = result[:num_train_samples], result[num_train_samples:]\n",
    "train_labels, test_labels = label[:num_train_samples], label[num_train_samples:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40e38bd-f1ca-4462-a290-3c9a037fa185",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = np.array(train_labels)\n",
    "test_labels = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030e731f-cb7c-4303-b163-e02ef44f1dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_unit=32\n",
    "std_scale = preprocessing.StandardScaler().fit(train_data)\n",
    "X_normalized = std_scale.transform(train_data)\n",
    "train_data=np.reshape(X_normalized,(X_normalized.shape[0],shape_unit,shape_unit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fec1961-b9f7-428f-ad5e-49aec13078bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_scale = preprocessing.StandardScaler().fit(test_data)\n",
    "X_normalized = std_scale.transform(test_data)\n",
    "test_data=np.reshape(X_normalized,(X_normalized.shape[0],shape_unit,shape_unit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5f402e-a4ba-4a07-9e49-3b0267fa3abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# std_scale = preprocessing.StandardScaler().fit(test_data)\n",
    "np.save('alldata_tape_scaled_test.npy', test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b350c7-fe3b-4a38-964a-0b8b3922fd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f8d1a0-440b-4d49-aaa2-646a575cedfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848f1516-e234-4be2-92db-31f59e30cbe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.expand_dims(train_data, -1)\n",
    "test_data = np.expand_dims(test_data, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af632f6-362f-410f-a8ff-13bdd596c755",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db54fe43-1e90-49fa-9969-4aeb863b5efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(test_labels, return_counts=True)\n",
    "print(np.asarray((unique, counts)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03be9bf2-b02f-43b8-820e-268629dcf574",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af877c85-91e9-4f23-842d-3b145b11ea84",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3a75dc-0a96-4764-9a77-bdb30b83e04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f2b57b-66ba-4738-b9ea-4496ccc78803",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(30):\n",
    "    plt.matshow(train_data[i])\n",
    "    plt.title(train_labels[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16846fe8-3f31-4453-8eed-aeaf48ca6568",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    " temp_model = model_trainning_saving([32,32],50,\"alldata_tape_model\",train_data,train_labels,test_data,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb840b0-3476-410e-a3e1-5bb093df6664",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_result = temp_model.predict(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec1816e-d78f-444a-8d05-7394042ef693",
   "metadata": {},
   "source": [
    "### ESM and Geotop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61282f63-fba9-4d49-9743-8927ffb67cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c542b0-4ef2-4212-bd79-d3496fa02789",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding2[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be95f4d-45e5-4426-ba68-8509694a107f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dgms = gdr.DiagramSelector(use=True, point_type='finite').fit_transform(embedding2_geotop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681d80a7-b312-4328-8a30-c991c1718011",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 1681\n",
    "result = concate_embedding_geotop(numpy_array,dgms,dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0845ac64-27d7-4352-9040-ac85d0bf89b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16aa7fa2-0b21-4840-9e99-a442c4678d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6e1fc8-e73d-44dd-95d2-52d7926b0956",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the dataset\n",
    "num_samples = len(result)\n",
    "num_train_samples = int(0.8 * num_samples)  # 80% for training, 20% for testing\n",
    "\n",
    "# Split data and labels into training and testing sets\n",
    "train_data, test_data = result[:num_train_samples], result[num_train_samples:]\n",
    "train_labels, test_labels = label[:num_train_samples], label[num_train_samples:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc8e81f-a13e-480f-95e3-9b4df4b6e6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('alldata_esm_scaled_test.npy', test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd462c0f-a609-45d8-8991-ab15035cb68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = np.array(train_labels)\n",
    "test_labels = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a8525d-ab02-4370-9378-1fd59ceb070c",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_unit=41\n",
    "std_scale = preprocessing.StandardScaler().fit(train_data)\n",
    "X_normalized = std_scale.transform(train_data)\n",
    "train_data=np.reshape(X_normalized,(X_normalized.shape[0],shape_unit,shape_unit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31574d63-6387-46c9-afa1-3fce09e46b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_scale = preprocessing.StandardScaler().fit(test_data)\n",
    "X_normalized = std_scale.transform(test_data)\n",
    "test_data=np.reshape(X_normalized,(X_normalized.shape[0],shape_unit,shape_unit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8217cf9d-0848-4044-9156-de5d7fd594a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('alldata_esm_scaled_test.npy', test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db945b98-c5db-4553-a1c7-427e79edb3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.expand_dims(train_data, -1)\n",
    "test_data = np.expand_dims(test_data, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b93100-622a-44be-879f-977cd3aecd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(train_labels, return_counts=True)\n",
    "print(np.asarray((unique, counts)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef4c499-30b6-44a8-a530-280982151635",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0e9165-48ec-47cb-8326-d1d9732dafc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db98244b-2439-4c64-b368-f3102248d739",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(30):\n",
    "    plt.matshow(train_data[i])\n",
    "    plt.title(train_labels[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c559a7-bce3-477f-b8a1-03f97a7cb22e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    " rest = model_trainning_saving([41,41],45,\"esm_model_alldata_new\",train_data,train_labels,test_data,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf5d0bf-0a4a-4fac-8f64-a351862ed1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_result = rest.predict(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa19a84-295d-49ea-b74f-7fdde0b4af9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "for u in temp_result:\n",
    "    if u>0.5:\n",
    "        print(\"*** \",i,\" *** \",train_labels[i])\n",
    "        print(round(u[0],4))\n",
    "    i = i+1\n",
    "print(\"***************\")\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5008f7d-2213-4237-9ed1-633ac9fdf475",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.value_counts(pd.DataFrame(train_labels)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b46922a-f264-40a0-a7b7-8b8303f1528f",
   "metadata": {},
   "source": [
    "### TAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a368223-872e-4b66-965d-2b7ddb2961f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = np.concatenate((embedded, np.zeros((embedded.shape[0],16))), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7b22c3-a5c1-4ad7-bc06-a0b1d0006dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the dataset\n",
    "num_samples = len(result)\n",
    "num_train_samples = int(0.8 * num_samples)  # 80% for training, 20% for testing\n",
    "\n",
    "# Split data and labels into training and testing sets\n",
    "train_data, test_data = result[:num_train_samples], result[num_train_samples:]\n",
    "train_labels, test_labels = label[:num_train_samples], label[num_train_samples:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f7cc5c-3b03-4ea1-a3b4-88b0e4342446",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = np.array(train_labels)\n",
    "test_labels = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45872288-1bb1-4da5-90f6-64bfcd35432b",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_unit=28\n",
    "std_scale = preprocessing.StandardScaler().fit(train_data)\n",
    "X_normalized = std_scale.transform(train_data)\n",
    "train_data=np.reshape(X_normalized,(X_normalized.shape[0],shape_unit,shape_unit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0413bc-cfb8-4121-9c4f-ff0622bbe068",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_scale = preprocessing.StandardScaler().fit(test_data)\n",
    "X_normalized = std_scale.transform(test_data)\n",
    "test_data=np.reshape(X_normalized,(X_normalized.shape[0],shape_unit,shape_unit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3590482b-0b63-424c-9fdf-73407d271b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.expand_dims(train_data, -1)\n",
    "test_data = np.expand_dims(test_data, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a6c7bb-f194-4522-ac2b-4f0f5ba7c7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(train_labels, return_counts=True)\n",
    "print(np.asarray((unique, counts)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af7e84e-9035-435f-ba5e-dad71b7137c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9113b6-334e-41e2-8cd8-09ef254328d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(30):\n",
    "    plt.matshow(train_data[i])\n",
    "    plt.title(train_labels[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c93df76-dabc-4e8b-aea7-6171864c3550",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    " model_trainning_saving([28,28],45,\"tape_only_model\",train_data,train_labels,test_data,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625bda14-6b9e-44bb-9910-39efb4a9910f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5605b403-032a-41c0-bbb6-72fe61b44e7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc3066ec-d34e-432a-81f5-c2232c6c4e43",
   "metadata": {},
   "source": [
    "### Geotop of TAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e6aad5-dcbb-4eff-9952-d7b8d6922abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dgms = gdr.DiagramSelector(use=True, point_type='finite').fit_transform(embedding_geotop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bce69eb-9879-4632-8431-ef25d9e7af85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#15*15\n",
    "dim = 225\n",
    "result = concat_embedding_geotop(dgms,dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfba3ab3-9841-485a-a1fd-a4207c20f0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the dataset\n",
    "num_samples = len(result)\n",
    "num_train_samples = int(0.8 * num_samples)  # 80% for training, 20% for testing\n",
    "\n",
    "# Split data and labels into training and testing sets\n",
    "train_data, test_data = result[:num_train_samples], result[num_train_samples:]\n",
    "train_labels, test_labels = label[:num_train_samples], label[num_train_samples:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ef921b-af12-4588-af72-d2a493faaf48",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = np.array(train_labels)\n",
    "test_labels = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233a74cc-1de2-4144-82e7-e1f67eeb1fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_unit=15\n",
    "std_scale = preprocessing.StandardScaler().fit(train_data)\n",
    "X_normalized = std_scale.transform(train_data)\n",
    "train_data=np.reshape(X_normalized,(X_normalized.shape[0],shape_unit,shape_unit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e202af-ff1d-4ba5-a6b5-c3e16cbe9e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_scale = preprocessing.StandardScaler().fit(test_data)\n",
    "X_normalized = std_scale.transform(test_data)\n",
    "test_data=np.reshape(X_normalized,(X_normalized.shape[0],shape_unit,shape_unit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0a8fd6-e67d-483e-adfb-4b0cc3115d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.expand_dims(train_data, -1)\n",
    "test_data = np.expand_dims(test_data, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecf42a2-495e-4ae0-b7c4-7dae84e91e43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(30):\n",
    "    plt.matshow(train_data[i])\n",
    "    plt.title(train_labels[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157642c4-c493-4af4-a2b2-3797b0018f0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    " model_trainning_saving([15,15],45,\"geotop_of_tape_model\",train_data,train_labels,test_data,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e030a072-24d7-463f-b450-d6590e94028d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
